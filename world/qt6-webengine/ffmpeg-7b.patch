commit 62274859104bd828373ae406aa9309e610449ac5
Author: Ted Meyer <tmathmeyer@chromium.org>
Date:   Fri Mar 22 19:56:55 2024 +0000

    Replace deprecated use of AVCodecContext::reordered_opaque
    
    We can use the AV_CODEC_FLAG_COPY_OPAQUE flag on the codec context
    now to trigger timestamp propagation.
    
    Bug: 330573128
    Change-Id: I6bc57241a35ab5283742aad8d42acb4dc5e85858
    Reviewed-on: https://chromium-review.googlesource.com/c/chromium/src/+/5384308
    Commit-Queue: Ted (Chromium) Meyer <tmathmeyer@chromium.org>
    Reviewed-by: Dan Sanders <sandersd@chromium.org>
    Cr-Commit-Position: refs/heads/main@{#1277051}

diff --git a/media/filters/ffmpeg_video_decoder.cc b/media/filters/ffmpeg_video_decoder.cc
index bd75477feeabb..8a658a58caac5 100644
--- a/media/filters/ffmpeg_video_decoder.cc
+++ b/media/filters/ffmpeg_video_decoder.cc
@@ -134,7 +134,7 @@ bool FFmpegVideoDecoder::IsCodecSupported(VideoCodec codec) {
 }
 
 FFmpegVideoDecoder::FFmpegVideoDecoder(MediaLog* media_log)
-    : media_log_(media_log) {
+    : media_log_(media_log), timestamp_map_(128) {
   DVLOG(1) << __func__;
   DETACH_FROM_SEQUENCE(sequence_checker_);
 }
@@ -363,8 +363,10 @@ bool FFmpegVideoDecoder::FFmpegDecode(const DecoderBuffer& buffer) {
     DCHECK(packet->data);
     DCHECK_GT(packet->size, 0);
 
-    // Let FFmpeg handle presentation timestamp reordering.
-    codec_context_->reordered_opaque = buffer.timestamp().InMicroseconds();
+    const int64_t timestamp = buffer.timestamp().InMicroseconds();
+    const TimestampId timestamp_id = timestamp_id_generator_.GenerateNextId();
+    timestamp_map_.Put(std::make_pair(timestamp_id, timestamp));
+    packet->opaque = reinterpret_cast<void*>(timestamp_id.GetUnsafeValue());
   }
   FFmpegDecodingLoop::DecodeStatus decode_status = decoding_loop_->DecodePacket(
       packet, base::BindRepeating(&FFmpegVideoDecoder::OnNewFrame,
@@ -423,7 +425,12 @@ bool FFmpegVideoDecoder::OnNewFrame(AVFrame* frame) {
   }
   gfx::Size natural_size = aspect_ratio.GetNaturalSize(visible_rect);
 
-  const auto pts = base::Microseconds(frame->reordered_opaque);
+  const auto ts_id = TimestampId(reinterpret_cast<size_t>(frame->opaque));
+  const auto ts_lookup = timestamp_map_.Get(ts_id);
+  if (ts_lookup == timestamp_map_.end()) {
+    return false;
+  }
+  const auto pts = base::Microseconds(std::get<1>(*ts_lookup));
   auto video_frame = VideoFrame::WrapExternalDataWithLayout(
       opaque->layout, visible_rect, natural_size, opaque->data, opaque->size,
       pts);
@@ -498,8 +505,10 @@ bool FFmpegVideoDecoder::ConfigureDecoder(const VideoDecoderConfig& config,
   codec_context_->thread_count = GetFFmpegVideoDecoderThreadCount(config);
   codec_context_->thread_type =
       FF_THREAD_SLICE | (low_delay ? 0 : FF_THREAD_FRAME);
+
   codec_context_->opaque = this;
   codec_context_->get_buffer2 = GetVideoBufferImpl;
+  codec_context_->flags |= AV_CODEC_FLAG_COPY_OPAQUE;
 
   if (base::FeatureList::IsEnabled(kFFmpegAllowLists)) {
     // Note: FFmpeg will try to free this string, so we must duplicate it.
diff --git a/media/filters/ffmpeg_video_decoder.h b/media/filters/ffmpeg_video_decoder.h
index d02cb89c3ddf7..0a2de1c623fff 100644
--- a/media/filters/ffmpeg_video_decoder.h
+++ b/media/filters/ffmpeg_video_decoder.h
@@ -7,10 +7,12 @@
 
 #include <memory>
 
+#include "base/containers/lru_cache.h"
 #include "base/functional/callback.h"
 #include "base/memory/raw_ptr.h"
 #include "base/memory/scoped_refptr.h"
 #include "base/sequence_checker.h"
+#include "base/types/id_type.h"
 #include "media/base/supported_video_decoder_config.h"
 #include "media/base/video_decoder.h"
 #include "media/base/video_decoder_config.h"
@@ -87,6 +89,20 @@ class MEDIA_EXPORT FFmpegVideoDecoder : public VideoDecoder {
   // FFmpeg structures owned by this object.
   std::unique_ptr<AVCodecContext, ScopedPtrAVFreeContext> codec_context_;
 
+  // The gist here is that timestamps need to be 64 bits to store microsecond
+  // precision. A 32 bit integer would overflow at ~35 minutes at this level of
+  // precision. We can't cast the timestamp to the void ptr object used by the
+  // opaque field in ffmpeg then, because it would lose data on a 32 bit build.
+  // However, we don't actually have 2^31 timestamped frames in a single
+  // playback, so it's fine to use the 32 bit value as a key in a map which
+  // contains the actual timestamps. Additionally, we've in the past set 128
+  // outstanding frames for re-ordering as a limit for cross-thread decoding
+  // tasks, so we'll do that here too with the LRU cache.
+  using TimestampId = base::IdType<int64_t, size_t, 0>;
+
+  TimestampId::Generator timestamp_id_generator_;
+  base::LRUCache<TimestampId, int64_t> timestamp_map_;
+
   VideoDecoderConfig config_;
 
   scoped_refptr<FrameBufferPool> frame_pool_;
diff --git a/media/ffmpeg/ffmpeg_common.cc b/media/ffmpeg/ffmpeg_common.cc
index 3331581a6fee6..69539fd6594ec 100644
--- a/media/ffmpeg/ffmpeg_common.cc
+++ b/media/ffmpeg/ffmpeg_common.cc
@@ -404,7 +404,9 @@ bool AVCodecContextToAudioDecoderConfig(const AVCodecContext* codec_context,
 
     // TODO(dalecurtis): Just use the profile from the codec context if ffmpeg
     // ever starts supporting xHE-AAC.
-    if (codec_context->profile == FF_PROFILE_UNKNOWN) {
+    constexpr uint8_t kXHEAAc = 41;
+    if (codec_context->profile == FF_PROFILE_UNKNOWN ||
+        codec_context->profile == kXHEAAc) {
       // Errors aren't fatal here, so just drop any MediaLog messages.
       NullMediaLog media_log;
       mp4::AAC aac_parser;
diff --git a/media/ffmpeg/ffmpeg_regression_tests.cc b/media/ffmpeg/ffmpeg_regression_tests.cc
index 05dcb1cd62c75..866f446698947 100644
--- a/media/ffmpeg/ffmpeg_regression_tests.cc
+++ b/media/ffmpeg/ffmpeg_regression_tests.cc
@@ -90,16 +90,16 @@ FFMPEG_TEST_CASE(Cr62127,
                  PIPELINE_ERROR_DECODE,
                  PIPELINE_ERROR_DECODE);
 FFMPEG_TEST_CASE(Cr93620, "security/93620.ogg", PIPELINE_OK, PIPELINE_OK);
-FFMPEG_TEST_CASE(Cr100492,
-                 "security/100492.webm",
-                 DECODER_ERROR_NOT_SUPPORTED,
-                 DECODER_ERROR_NOT_SUPPORTED);
+FFMPEG_TEST_CASE(Cr100492, "security/100492.webm", PIPELINE_OK, PIPELINE_OK);
 FFMPEG_TEST_CASE(Cr100543, "security/100543.webm", PIPELINE_OK, PIPELINE_OK);
 FFMPEG_TEST_CASE(Cr101458,
                  "security/101458.webm",
                  PIPELINE_ERROR_DECODE,
                  PIPELINE_ERROR_DECODE);
-FFMPEG_TEST_CASE(Cr108416, "security/108416.webm", PIPELINE_OK, PIPELINE_OK);
+FFMPEG_TEST_CASE(Cr108416,
+                 "security/108416.webm",
+                 PIPELINE_ERROR_DECODE,
+                 PIPELINE_ERROR_DECODE);
 FFMPEG_TEST_CASE(Cr110849,
                  "security/110849.mkv",
                  DEMUXER_ERROR_COULD_NOT_OPEN,
@@ -154,7 +154,10 @@ FFMPEG_TEST_CASE(Cr234630b,
                  "security/234630b.mov",
                  DEMUXER_ERROR_NO_SUPPORTED_STREAMS,
                  DEMUXER_ERROR_NO_SUPPORTED_STREAMS);
-FFMPEG_TEST_CASE(Cr242786, "security/242786.webm", PIPELINE_OK, PIPELINE_OK);
+FFMPEG_TEST_CASE(Cr242786,
+                 "security/242786.webm",
+                 PIPELINE_OK,
+                 PIPELINE_ERROR_DECODE);
 // Test for out-of-bounds access with slightly corrupt file (detection logic
 // thinks it's a MONO file, but actually contains STEREO audio).
 FFMPEG_TEST_CASE(Cr275590,
@@ -372,8 +375,8 @@ FFMPEG_TEST_CASE(WEBM_2,
                  DEMUXER_ERROR_NO_SUPPORTED_STREAMS);
 FFMPEG_TEST_CASE(WEBM_4,
                  "security/out.webm.68798.1929",
-                 DECODER_ERROR_NOT_SUPPORTED,
-                 DECODER_ERROR_NOT_SUPPORTED);
+                 PIPELINE_OK,
+                 PIPELINE_OK);
 FFMPEG_TEST_CASE(WEBM_5, "frame_size_change.webm", PIPELINE_OK, PIPELINE_OK);
 
 // General MKV test cases.
diff --git a/media/filters/audio_decoder_unittest.cc b/media/filters/audio_decoder_unittest.cc
index a31823cfe3b58..e43f408b79e5c 100644
--- a/media/filters/audio_decoder_unittest.cc
+++ b/media/filters/audio_decoder_unittest.cc
@@ -484,7 +484,7 @@ constexpr TestParams kXheAacTestParams[] = {
      }},
      0,
      29400,
-     CHANNEL_LAYOUT_MONO,
+     CHANNEL_LAYOUT_UNSUPPORTED,
      AudioCodecProfile::kXHE_AAC},
 #endif
     {AudioCodec::kAAC,
diff --git a/media/filters/audio_file_reader_unittest.cc b/media/filters/audio_file_reader_unittest.cc
index c0cc568d63019..edf9470f2f8b3 100644
--- a/media/filters/audio_file_reader_unittest.cc
+++ b/media/filters/audio_file_reader_unittest.cc
@@ -62,15 +62,14 @@ class AudioFileReaderTest : public testing::Test {
   // Verify packets are consistent across demuxer runs.  Reads the first few
   // packets and then seeks back to the start timestamp and verifies that the
   // hashes match on the packets just read.
-  void VerifyPackets() {
-    const int kReads = 3;
+  void VerifyPackets(int packet_reads) {
     const int kTestPasses = 2;
 
     AVPacket packet;
     base::TimeDelta start_timestamp;
     std::vector<std::string> packet_md5_hashes_;
     for (int i = 0; i < kTestPasses; ++i) {
-      for (int j = 0; j < kReads; ++j) {
+      for (int j = 0; j < packet_reads; ++j) {
         ASSERT_TRUE(reader_->ReadPacketForTesting(&packet));
 
         // On the first pass save the MD5 hash of each packet, on subsequent
@@ -99,7 +98,8 @@ class AudioFileReaderTest : public testing::Test {
                int sample_rate,
                base::TimeDelta duration,
                int frames,
-               int expected_frames) {
+               int expected_frames,
+               int packet_reads = 3) {
     Initialize(fn);
     ASSERT_TRUE(reader_->Open());
     EXPECT_EQ(channels, reader_->channels());
@@ -113,7 +113,7 @@ class AudioFileReaderTest : public testing::Test {
       EXPECT_EQ(reader_->HasKnownDuration(), false);
     }
     if (!packet_verification_disabled_)
-      ASSERT_NO_FATAL_FAILURE(VerifyPackets());
+      ASSERT_NO_FATAL_FAILURE(VerifyPackets(packet_reads));
     ReadAndVerify(hash, expected_frames);
   }
 
@@ -220,7 +220,7 @@ TEST_F(AudioFileReaderTest, AAC_ADTS) {
 }
 
 TEST_F(AudioFileReaderTest, MidStreamConfigChangesFail) {
-  RunTestFailingDecode("midstream_config_change.mp3", 42624);
+  RunTestFailingDecode("midstream_config_change.mp3", 0);
 }
 #endif
 
@@ -230,7 +230,7 @@ TEST_F(AudioFileReaderTest, VorbisInvalidChannelLayout) {
 
 TEST_F(AudioFileReaderTest, WaveValidFourChannelLayout) {
   RunTest("4ch.wav", "131.71,38.02,130.31,44.89,135.98,42.52,", 4, 44100,
-          base::Microseconds(100001), 4411, 4410);
+          base::Microseconds(100001), 4411, 4410, /*packet_reads=*/2);
 }
 
 TEST_F(AudioFileReaderTest, ReadPartialMP3) {
diff --git a/media/filters/ffmpeg_video_decoder.cc b/media/filters/ffmpeg_video_decoder.cc
index 8a658a58caac5..9d6ed8aeb5c48 100644
--- a/media/filters/ffmpeg_video_decoder.cc
+++ b/media/filters/ffmpeg_video_decoder.cc
@@ -213,10 +213,6 @@ int FFmpegVideoDecoder::GetVideoBuffer(struct AVCodecContext* codec_context,
     frame->linesize[plane] = layout->planes()[plane].stride;
   }
 
-  // This seems unsafe, given threaded decoding.  However, `reordered_opaque` is
-  // also going away upstream, so we need a whole new mechanism either way.
-  frame->reordered_opaque = codec_context->reordered_opaque;
-
   // This will be freed by `ReleaseVideoBufferImpl`.
   auto* opaque = new OpaqueData(fb_priv, frame_pool_, data, allocation_size,
                                 std::move(*layout));
diff --git a/media/filters/audio_file_reader.cc b/media/filters/audio_file_reader.cc
index e1be5aa9a5b13..951c003956fb5 100644
--- a/media/filters/audio_file_reader.cc
+++ b/media/filters/audio_file_reader.cc
@@ -243,18 +243,10 @@ bool AudioFileReader::OnNewFrame(
   // silence from being output. In the case where we are also discarding some
   // portion of the packet (as indicated by a negative pts), we further want to
   // adjust the duration downward by however much exists before zero.
-#if BUILDFLAG(USE_SYSTEM_FFMPEG)
-  if (audio_codec_ == AudioCodec::kAAC && frame->pkt_duration) {
-#else
   if (audio_codec_ == AudioCodec::kAAC && frame->duration) {
-#endif  // BUILDFLAG(USE_SYSTEM_FFMPEG)
     const base::TimeDelta pkt_duration = ConvertFromTimeBase(
         glue_->format_context()->streams[stream_index_]->time_base,
-#if BUILDFLAG(USE_SYSTEM_FFMPEG)
-        frame->pkt_duration + std::min(static_cast<int64_t>(0), frame->pts));
-#else
         frame->duration + std::min(static_cast<int64_t>(0), frame->pts));
-#endif  // BUILDFLAG(USE_SYSTEM_FFMPEG)
     const base::TimeDelta frame_duration =
         base::Seconds(frames_read / static_cast<double>(sample_rate_));
 
